{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vic-torr/thesis-experiments/blob/main/rsp_swin_t_13_11_22_swin_14_epoch_imagenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R7FgPDy0Lpi"
      },
      "source": [
        "# Set Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qlPfbkZzlJ_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "834d7149-59f2-429a-df3f-445b6f35057a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Archive:  /content/drive/MyDrive/Colab-Notebooks/datasets/planet.zip\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "RunningInCOLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if RunningInCOLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    #!unzip /content/drive/MyDrive/Colab-Notebooks/datasets/planet.zip -d /content/drive/MyDrive/Colab-Notebooks/datasets/planet\n",
        "    !unzip -n /content/drive/MyDrive/Colab-Notebooks/datasets/planet.zip -d /content/;\n",
        "    checkpoint_path = '/content/drive/MyDrive/Colab-Notebooks/checkpoints/'\n",
        "    dataset_dir=\"/content/planet/\"\n",
        "    #dataset_dir=\"/content/drive/MyDrive/Colab-Notebooks/datasets/planet/\"\n",
        "else:\n",
        "    home = os.environ['HOME']\n",
        "    dataset_dir = home+\"/UFMG/Thesis/datasets/planet\"\n",
        "    checkpoint_path = home+'/UFMG/Thesis/Experiments/checkpoints/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2pbhSvzCZo_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ecd9392-6198-445c-feac-92152a44f0fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0.post1)\n",
            "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.7/dist-packages (0.4.10)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (0.3.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (5.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.7/dist-packages (1.7.1)\n",
            "Requirement already satisfied: virtualenv in /usr/local/lib/python3.7/dist-packages (20.16.7)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.6.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.6.11)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.7/dist-packages (0.1.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (21.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly) (1.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly) (8.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (4.13.0)\n",
            "Requirement already satisfied: filelock<4,>=3.4.1 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (3.8.0)\n",
            "Requirement already satisfied: platformdirs<3,>=2.4 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (2.5.4)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (0.3.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.3->virtualenv) (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.10.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.10.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.25.11)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.6)\n"
          ]
        }
      ],
      "source": [
        "if RunningInCOLAB:\n",
        "    %pip install torch torchvision sklearn pytorch-ignite dill tqdm plotly matplotlib torchinfo virtualenv opencv-python datasets evaluate timm yacs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayfizw-CuDfy"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "from torchinfo import summary\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
        "from torch.optim import AdamW, Adam\n",
        "from torchvision import transforms as T, models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "from torch import nn, Tensor\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "from sklearn.metrics import fbeta_score, confusion_matrix\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.manifold import TSNE\n",
        "import cv2\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np  # Torch wrapper for Numpy\n",
        "from PIL import Image\n",
        "import os\n",
        "import gc\n",
        "import random\n",
        "import threading\n",
        "from copy import copy, deepcopy\n",
        "from time import time\n",
        "from glob import glob\n",
        "from tqdm.notebook import tqdm\n",
        "from collections import Counter\n",
        "import dill as pickle\n",
        "\n",
        "from plotly import graph_objects as go\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozySfe4T0Lp0"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    \"\"\"\n",
        "    Seeds basic parameters for reproductibility of results\n",
        "\n",
        "    Arguments:\n",
        "        seed {int} -- Number of the seed\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "seed_everything(1001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74ipZquTlJ_W"
      },
      "outputs": [],
      "source": [
        "!ls $dataset_dir\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddEsH8tA0Lp3"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rv9sdalowQ4g"
      },
      "outputs": [],
      "source": [
        "path = dataset_dir\n",
        "path_train = os.path.join(path, \"train-jpg\")\n",
        "path_test = os.path.join(path, \"test-jpg\")\n",
        "total_train_files = len(os.listdir(path_train))\n",
        "print(\n",
        "    f\"train files: {total_train_files}, \"\n",
        "    f\"test files: {len(os.listdir(path_test))}\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3O7DGVCjcmVg"
      },
      "outputs": [],
      "source": [
        "im = Image.open(path_train+'/train_32.jpg')\n",
        "image_file = im.convert(\"RGB\")\n",
        "display(image_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvFDqEGVz6Mi"
      },
      "outputs": [],
      "source": [
        "path_class = os.path.join(path, \"train_classes.csv\")\n",
        "df_class = pd.read_csv(path_class)\n",
        "print(df_class.shape)\n",
        "df_class.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmJIdadoK0eu"
      },
      "outputs": [],
      "source": [
        "df_class[\"list_tags\"] = df_class.tags.str.split(\" \")\n",
        "row_tags = df_class.list_tags.values\n",
        "tags = [tag for row in row_tags for tag in row]\n",
        "counter_tags = Counter(tags)\n",
        "df_tags = pd.DataFrame(\n",
        "    {\"tag\": counter_tags.keys(), \"total\": counter_tags.values()}\n",
        ").sort_values(\"total\")\n",
        "\n",
        "#fig = px.bar(df_tags, x=\"total\", y=\"tag\", orientation=\"h\", color=\"total\",)\n",
        "#fig.update_layout(title=\"Class distribution\")\n",
        "# fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0t6F8nGBoBUM"
      },
      "outputs": [],
      "source": [
        "classes = df_tags[\"total\"].sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpRalqsxSUhq"
      },
      "outputs": [],
      "source": [
        "RARE_CLASSES = [\n",
        "    \"bare_ground\", \"selective_logging\", \"artisinal_mine\", \"blooming\", \"slash_burn\", \"blow_down\", \"conventional_mine\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgxUyE9U0Lp_"
      },
      "outputs": [],
      "source": [
        "df_train, df_val = train_test_split(df_class, test_size=.2)\n",
        "\n",
        "for rare_class in RARE_CLASSES:\n",
        "    total_train = df_train.loc[df_train.tags.str.contains(rare_class)].shape[0]\n",
        "    total_val = df_val.loc[df_val.tags.str.contains(rare_class)].shape[0]\n",
        "    print(\n",
        "        f\"train {rare_class}: {100 * total_train / df_train.shape[0]:.4f}% ({total_train})\")\n",
        "    print(\n",
        "        f\"val {rare_class}: {100 * total_val / df_val.shape[0]:.4f}% ({total_val})\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtNv0YJvgn__"
      },
      "outputs": [],
      "source": [
        "all_tags = list(set(tags))\n",
        "N_tags = len(all_tags)\n",
        "fig, axes = plt.subplots(4, (N_tags//4)+1, figsize=(20, 20))\n",
        "for idx, tag in enumerate(all_tags):\n",
        "    filename = df_class.loc[df_class.tags.str.contains(\n",
        "        tag)].image_name.values[0]\n",
        "    img = cv2.imread(os.path.join(path_train, filename+\".jpg\"))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    idx_col = idx // 4\n",
        "    idx_row = idx % 4\n",
        "    axes[idx_row][idx_col].set_title(tag)\n",
        "    axes[idx_row][idx_col].imshow(img)\n",
        "axes[1][-1].remove()\n",
        "axes[2][-1].remove()\n",
        "axes[3][-1].remove()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4B833MuuDgi"
      },
      "outputs": [],
      "source": [
        "def load_img(path_file):\n",
        "    img = cv2.imread(path_file)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (100, 100), cv2.INTER_LINEAR).astype(float)\n",
        "    img = cv2.normalize(img, None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
        "    img = img.reshape(1, -1)\n",
        "    return img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHaNDRQ4uDgs"
      },
      "outputs": [],
      "source": [
        "filenames = df_class.image_name.sample(600).values\n",
        "path_files = [os.path.join(path_train, filename+\".jpg\")\n",
        "              for filename in filenames]\n",
        "X_train_sample = np.vstack([load_img(path_file) for path_file in path_files])\n",
        "X_train_sample.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5uPlujMuDg5"
      },
      "outputs": [],
      "source": [
        "def fetch_img(path_file, h, w):\n",
        "    img = cv2.imread(path_file)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (h*2, w*2), cv2.INTER_LINEAR)\n",
        "    return img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ev8b3DzpuDg8"
      },
      "outputs": [],
      "source": [
        "def tsne_analysis():\n",
        "\n",
        "    tsne = TSNE(\n",
        "        n_components=2,\n",
        "        init=\"random\",\n",
        "        random_state=101,\n",
        "        method=\"barnes_hut\",\n",
        "        n_iter=500,\n",
        "        verbose=2,\n",
        "    )\n",
        "    X_embedded = tsne.fit_transform(X_train_sample)\n",
        "    X_embedded.shape\n",
        "\n",
        "    size_img = 1000\n",
        "    offset_img = 50\n",
        "    h = w = int(offset_img / 2)\n",
        "\n",
        "    X_scaled = (X_embedded - X_embedded.min(0)) / \\\n",
        "        (X_embedded.max(0) - X_embedded.min(0))\n",
        "    X_scaled = (X_scaled * size_img).astype(int)\n",
        "    X_scaled = np.clip(X_scaled, offset_img, size_img-offset_img)\n",
        "\n",
        "    img_tsne = np.ones((size_img+2*offset_img, size_img+2 *\n",
        "                       offset_img, 3), dtype=np.uint8) * 255\n",
        "    for idx in range(X_scaled.shape[0]):\n",
        "        x, y = X_scaled[idx][0], X_scaled[idx][1]\n",
        "        img = fetch_img(path_files[idx], h, w)\n",
        "        img_tsne[x-w:x+w, y-h:y+h, :] = img\n",
        "\n",
        "    fig = plt.figure(figsize=(12, 12))\n",
        "    plt.imshow(img_tsne)\n",
        "    plt.axis(\"off\")\n",
        "# tsne_analysis()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFlVwBvw0LqC"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMIuFAHl0LqD"
      },
      "outputs": [],
      "source": [
        "# Rsp swin t from https://github.com/ViTAE-Transformer/ViTAE-Transformer-Remote-Sensing\n",
        "# loss function imbalanced classes\n",
        "BATCH_SIZE = 4\n",
        "if RunningInCOLAB:\n",
        "    BATCH_SIZE = 48\n",
        "FEATURES = 17\n",
        "IMG_SIZE = 224\n",
        "LR = 5e-4\n",
        "LR_STEP_SIZE = 10\n",
        "GAMMA = 0.9\n",
        "N_EPOCHS = 5\n",
        "VERSION = 'release'\n",
        "PRETRAIN_WEIGHTS = 'IMAGENET1K_V1'\n",
        "PRETRAIN_WEIGHTS = 'rsp-swin-t-ckpt.pth'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPupsdkCjdBx"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"BATCH_SIZE\": BATCH_SIZE,\n",
        "    \"IMG_SIZE\": IMG_SIZE,\n",
        "    \"LR\": LR,\n",
        "    \"LR_STEP_SIZE\": LR_STEP_SIZE,\n",
        "    \"GAMMA\": GAMMA,\n",
        "    \"N_EPOCHS\": N_EPOCHS,\n",
        "    \"VERSION\": VERSION,\n",
        "    \"PRETRAIN_WEIGHTS\": PRETRAIN_WEIGHTS,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z01_X8TImhwr"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    os.remove(checkpoint_path+f\"train_results_{VERSION}.pkl\")\n",
        "    os.remove(checkpoint_path+f\"swin_t_{VERSION}.pth\")\n",
        "    print(\"clear\")\n",
        "except:\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1yn3eXP0LqD"
      },
      "source": [
        "# Dataset prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6C8u-bTwuDhF"
      },
      "outputs": [],
      "source": [
        "# create image augmentations\n",
        "transform_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        T.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225],\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "transform_val = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        T.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225],\n",
        "        )\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpPReVzluDhS"
      },
      "outputs": [],
      "source": [
        "class AmazonDatasetError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "class AmazonDataset(Dataset):\n",
        "    def __init__(self, df, ohe_tags, transform, path, is_train=True, idx_tta=None):\n",
        "        super().__init__()\n",
        "        self.df = df\n",
        "        self.ohe_tags = ohe_tags\n",
        "        self.transform = transform_train\n",
        "        if isinstance(path, str):\n",
        "            self.paths = [path]\n",
        "        elif isinstance(path, (list, tuple)):\n",
        "            self.paths = path\n",
        "        else:\n",
        "            raise AmazonDatasetError(\n",
        "                f\"Path type must be str, list or tuple, got: {type(path)}\")\n",
        "        self.is_train = is_train\n",
        "        self.idx_tta = idx_tta\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filename = self.df.iloc[idx].image_name + \".jpg\"\n",
        "        for path in self.paths:\n",
        "            if filename in os.listdir(path):\n",
        "                file_path = os.path.join(path, filename)\n",
        "                break\n",
        "        else:\n",
        "            raise AmazonDatasetError(\n",
        "                f\"Can't fetch {filename} among {self.paths}\")\n",
        "        image = Image.open(file_path).convert(\"RGB\")\n",
        "        label = self.ohe_tags[idx]\n",
        "        return image, label\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        imgs, labels = [], []\n",
        "        for (img, label) in batch:\n",
        "            img = self.transform(img)\n",
        "            img.permute(2, 0, 1)\n",
        "            imgs.append(img[None])\n",
        "            labels.append(label[None])\n",
        "        imgs = torch.cat(imgs).float()\n",
        "        labels = torch.cat(labels).float()\n",
        "        return imgs, labels\n",
        "\n",
        "    def load_img(self, idx, ax=None):\n",
        "        img, ohe_label = self[idx]\n",
        "        label = self.df.iloc[idx].tags\n",
        "        title = f\"{label} - {ohe_label} - {self.transform(img).shape}\"\n",
        "        if ax is None:\n",
        "            plt.imshow(img)\n",
        "            plt.title(title)\n",
        "        else:\n",
        "            ax.imshow(img)\n",
        "            ax.set_title(title)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5w0J_CbuDhe"
      },
      "outputs": [],
      "source": [
        "#from multiprocessing import set_start_method\n",
        "#multiprocessing_context = torch.multiprocessing.set_start_method('spawn')\n",
        "\n",
        "def get_data(df_train, df_val):\n",
        "\n",
        "    encoder = MultiLabelBinarizer()\n",
        "    ohe_tags_train = torch.tensor(\n",
        "        encoder.fit_transform(df_train.list_tags.values))\n",
        "    ohe_tags_val = torch.tensor(encoder.transform(df_val.list_tags.values))\n",
        "\n",
        "    ds_train = AmazonDataset(df_train, ohe_tags_train,\n",
        "                             transform_train, path=path_train)\n",
        "    ds_val = AmazonDataset(df_val, ohe_tags_val,\n",
        "                           transform_val, path=path_train)\n",
        "\n",
        "    sample_weights = ohe_tags_train.shape[0]/ohe_tags_train.sum(axis=0)\n",
        "    sample_weights = sample_weights.double()\n",
        "    sampler = torch.utils.data.WeightedRandomSampler(\n",
        "        sample_weights, len(sample_weights))\n",
        "\n",
        "    dl_train = DataLoader(\n",
        "        ds_train,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        collate_fn=ds_train.collate_fn,\n",
        "        # sampler=sampler,\n",
        "        shuffle=True,\n",
        "        prefetch_factor=2,\n",
        "        pin_memory=True,\n",
        "        num_workers=2,\n",
        "        drop_last=True,\n",
        "        # persistent_workers=True,\n",
        "        #multiprocessing_context = multiprocessing_context\n",
        "    )\n",
        "    dl_val = DataLoader(\n",
        "        ds_val,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        collate_fn=ds_val.collate_fn,\n",
        "        prefetch_factor=2,\n",
        "        pin_memory=True,\n",
        "        num_workers=2,\n",
        "        drop_last=True,\n",
        "        # persistent_workers=True,\n",
        "        #multiprocessing_context = multiprocessing_context\n",
        "    )\n",
        "\n",
        "    return ds_train, ds_val, dl_train, dl_val, encoder, ohe_tags_train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZN893yuuDhg"
      },
      "outputs": [],
      "source": [
        "ds_train, ds_val, dl_train, dl_val, encoder, ohe_tags_train = get_data(df_train, df_val)\n",
        "\n",
        "def untest_loader():\n",
        "  imgs, labels = next(iter(dl_train))\n",
        "  print(imgs.shape, labels.shape)\n",
        "\n",
        "  imgs, labels = next(iter(dl_train))\n",
        "  print(imgs.shape, labels.shape)\n",
        "\n",
        "ds_train.load_img(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BjxIOAR0LqG"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90y7bSte0LqH"
      },
      "outputs": [],
      "source": [
        "print(\"Available SWIN Models: \")\n",
        "# timm.list_models(\"swin*\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzRNWiMzGhEw"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "#model = models.swin_transformer.swin_t()\n",
        "model = timm.models.swin_tiny_patch4_window7_224()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbrUPq-zCekj"
      },
      "outputs": [],
      "source": [
        "# Test checkpoint\n",
        "def load_train_checkpoint(filename):\n",
        "    checkpoint = torch.load(filename, map_location=torch.device(device))\n",
        "    print(checkpoint.keys())\n",
        "    results = dict()\n",
        "    try:\n",
        "        results = pickle.load(\n",
        "            open(checkpoint_path+f\"train_results_{VERSION}.pkl\", \"rb\"))\n",
        "    except:\n",
        "        pass\n",
        "    #model.load_state_dict(checkpoint['model'], strict=False)\n",
        "    epoch = checkpoint['epoch']\n",
        "    #loss = checkpoint['loss']\n",
        "    model_state = checkpoint['model']\n",
        "\n",
        "    optimizer_state = checkpoint['optimizer']\n",
        "    lr_scheduler_state = checkpoint['lr_scheduler']\n",
        "    max_accuracy = checkpoint['max_accuracy']\n",
        "    epoch = checkpoint['epoch']\n",
        "    #config = checkpoint['config']\n",
        "    return checkpoint, results, epoch, model_state, optimizer_state, lr_scheduler_state, max_accuracy\n",
        "\n",
        "# Test checkpoint\n",
        "\n",
        "\n",
        "def save_train_checkpoint(checkpoint, results, version):\n",
        "    if os.path.isfile(checkpoint_path+f\"swin_t_{VERSION}.pth\"):\n",
        "        os.remove(checkpoint_path+f\"swin_t_{VERSION}.pth\")\n",
        "        os.remove(checkpoint_path+f\"train_results_{version}.pkl\")\n",
        "    checkpoint[\"config\"] = config\n",
        "    torch.save(checkpoint, checkpoint_path+f\"swin_t_{version}.pth\")\n",
        "    pickle.dump(results, open(checkpoint_path +\n",
        "                f\"train_results_{version}.pkl\", \"wb+\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwfPGGWo0LqH"
      },
      "outputs": [],
      "source": [
        "if (os.path.isfile(checkpoint_path+f\"swin_t_{VERSION}.pth\")):\n",
        "    filename = checkpoint_path+f\"swin_t_{VERSION}.pth\"\n",
        "    checkpoint, results, epoch, model_state, optimizer_state, lr_scheduler_state, max_accuracy = load_train_checkpoint(\n",
        "        filename)\n",
        "    recover_training = True\n",
        "    print(\"recover_training\")\n",
        "else:\n",
        "    recover_training = False\n",
        "    print(\"not recover_training\")\n",
        "    if PRETRAIN_WEIGHTS == 'IMAGENET1K_V1':\n",
        "        model = models.swin_transformer.swin_t(weights='IMAGENET1K_V1')\n",
        "        model_state = model.state_dict()\n",
        "        resulresults_checkpointts = {}\n",
        "    else:\n",
        "        filename = checkpoint_path+PRETRAIN_WEIGHTS\n",
        "        checkpoint, results_checkpoint, epoch, model_state, optimizer_state, lr_scheduler_state, max_accuracy = load_train_checkpoint(\n",
        "            filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5SWZCmmD1uZ"
      },
      "outputs": [],
      "source": [
        "print(sorted([k for k in model_state.keys()\n",
        "      if \"relative_position_bias_table\" in k]))\n",
        "print(sorted([k for k in model.state_dict().keys()\n",
        "      if \"relative_position_bias_table\" in k]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kIhJAvLMFYX"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISneaFJsuDht"
      },
      "outputs": [],
      "source": [
        "state_dict = model_state\n",
        "\n",
        "num_classes = 17\n",
        "swin_embed_dim = 768\n",
        "\n",
        "if recover_training:\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    info = model.load_state_dict(state_dict, strict=False)\n",
        "    model.head = torch.nn.Sequential(\n",
        "        nn.Linear(swin_embed_dim, num_classes), torch.nn.Sigmoid())\n",
        "\n",
        "else:\n",
        "    try:\n",
        "\n",
        "        # for param in model.parameters():\n",
        "        #  param.require_grad = False\n",
        "\n",
        "        # assuming that the head layer has 768 neurons, otherwise change it\n",
        "        model.head = nn.Linear(swin_embed_dim, num_classes)\n",
        "        #torch.nn.Sequential(model, torch.nn.Sigmoid())\n",
        "\n",
        "        model = model.to(device)\n",
        "\n",
        "        state_dict = model.state_dict()\n",
        "\n",
        "        # delete relative_position_index since we always re-init it\n",
        "        relative_position_index_keys = [\n",
        "            k for k in state_dict.keys() if \"relative_position_index\" in k]\n",
        "        for k in relative_position_index_keys:\n",
        "            del state_dict[k]\n",
        "\n",
        "        # delete relative_coords_table since we always re-init it\n",
        "        relative_position_index_keys = [\n",
        "            k for k in state_dict.keys() if \"relative_coords_table\" in k]\n",
        "        for k in relative_position_index_keys:\n",
        "            del state_dict[k]\n",
        "\n",
        "        # delete attn_mask since we always re-init it\n",
        "        attn_mask_keys = [k for k in state_dict.keys() if \"attn_mask\" in k]\n",
        "        for k in attn_mask_keys:\n",
        "            del state_dict[k]\n",
        "\n",
        "        state_dict = model_state\n",
        "        # bicubic interpolate relative_position_bias_table if not match\n",
        "        relative_position_bias_table_keys = [\n",
        "            k for k in state_dict.keys() if \"relative_position_bias_table\" in k]\n",
        "        print(relative_position_bias_table_keys)\n",
        "\n",
        "        # bicubic interpolate absolute_pos_embed if not match\n",
        "        absolute_pos_embed_keys = [\n",
        "            k for k in state_dict.keys() if \"absolute_pos_embed\" in k]\n",
        "        print(absolute_pos_embed_keys)\n",
        "\n",
        "        torch.nn.init.constant_(model.head.bias, 0.)\n",
        "        torch.nn.init.constant_(model.head.weight, 0.)\n",
        "        del state_dict['head.weight']\n",
        "        del state_dict['head.bias']\n",
        "\n",
        "        info = model.load_state_dict(state_dict, strict=False)\n",
        "        print(info)\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "    except:\n",
        "        ...\n",
        "\n",
        "    #model.head = torch.nn.Sequential(nn.Linear(swin_embed_dim, num_classes),torch.nn.Sigmoid())\n",
        "    # model.head = nn.Linear(swin_embed_dim, num_classes) # assuming that the head layer has 768 neurons, otherwise change it\n",
        "    #info = torch.nn.Sequential(model, torch.nn.Sigmoid())\n",
        "\n",
        "# model.to(device)\n",
        "#optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "\n",
        "print(info)\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxE4lyvEN7UC"
      },
      "outputs": [],
      "source": [
        "model.get_parameter(\"layers.2.blocks.4.mlp.fc1.bias\").requires_grad = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIeQ0uR6ORiJ"
      },
      "outputs": [],
      "source": [
        "model.get_parameter(\"layers.2.blocks.4.mlp.fc1.bias\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b36Ya4C9MKKO"
      },
      "outputs": [],
      "source": [
        "kl = list()\n",
        "unfreeze_param = [\"relative_position_index\",\n",
        "                  \"relative_coords_table\", \"attn_mask\", \"head\"]\n",
        "for k, v in model.state_dict().items():\n",
        "    for parameter in unfreeze_param:\n",
        "        try:\n",
        "            if parameter in k:\n",
        "                v.requires_grad = True\n",
        "                print(f\"unfreeze {k}\")\n",
        "                break\n",
        "            else:\n",
        "                v.requires_grad = False\n",
        "                kl.append(k)\n",
        "                print(\"freeze \", k)\n",
        "                break\n",
        "        except:\n",
        "            print('model doesnt have parameter ', k)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Og2vy9c0LqK"
      },
      "outputs": [],
      "source": [
        "[module for module in model.modules() if not isinstance(module, nn.Sequential)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b8bTtPE0LqK"
      },
      "source": [
        "# Train setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LXA6XXxCYKX"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "lr_scheduler = ReduceLROnPlateau(optimizer, cooldown=2, factor=0.5, verbose=True, patience=10)\n",
        "sample_weights = ohe_tags_train.shape[0]/ohe_tags_train.sum(axis=0)\n",
        "sample_weights = sample_weights.double().to(device)\n",
        "loss_fn = nn.BCEWithLogitsLoss(\n",
        "    pos_weight=sample_weights)  # Binary Cross Entropy\n",
        "sample_weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvLrcH549YXL"
      },
      "source": [
        "# Train Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42XGRULguDhw"
      },
      "outputs": [],
      "source": [
        "def train_batch(X, Y, model, loss_fn, optimizer):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    Y_hat = model(X.to(device))\n",
        "    batch_loss = loss_fn(Y_hat, Y.to(device))\n",
        "    batch_loss.backward()\n",
        "    optimizer.step()\n",
        "    Y_hat = Y_hat.detach()\n",
        "\n",
        "    return Y_hat, batch_loss.item()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_val_loss(X, Y, model, loss_fn):\n",
        "    model.eval()\n",
        "    Y_hat = model(X.to(device))\n",
        "    batch_loss = loss_fn(Y_hat, Y.to(device))\n",
        "    Y_hat = Y_hat.detach()\n",
        "\n",
        "    return Y_hat, batch_loss.item()\n",
        "# Test batch train\n",
        "#def unit_test_batch_train():\n",
        "  #X, Y = next(iter(dl_train))\n",
        "\n",
        "  #model.train()\n",
        "  #optimizer.zero_grad()\n",
        "  #Y_hat = model(X.to(device))\n",
        "  #Y_hat[Y_hat < 0]\n",
        "  #batch_loss = loss_fn(Y_hat, Y.to(device))\n",
        "  #Y_hat = Y_hat.detach()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5tdxp0zCMqWU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4i0Q_yil6SN"
      },
      "outputs": [],
      "source": [
        "def last_epoch(tensor, epoch_size, curr_pos):\n",
        "    return tensor[curr_pos - epoch_size: curr_pos]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVjYlNMcIy13"
      },
      "outputs": [],
      "source": [
        "np.zeros((4,2))[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDW48_xDIy14"
      },
      "outputs": [],
      "source": [
        "def init_arrays(train_baches_epoch, val_baches_epoch):\n",
        "    loss = dict()\n",
        "    loss[\"train\"] = np.zeros((N_EPOCHS,train_baches_epoch))\n",
        "    loss[\"val\"] = np.zeros((N_EPOCHS,train_baches_epoch))\n",
        "\n",
        "    score = dict()\n",
        "    score[\"val\"] = np.zeros(N_EPOCHS)\n",
        "    score[\"train\"] = np.zeros(N_EPOCHS)\n",
        "\n",
        "    y_epoch = {'train': dict(), 'val': dict()}\n",
        "    y_epoch[\"train\"][\"label\"] = torch.zeros((N_EPOCHS, train_baches_epoch, BATCH_SIZE, FEATURES))\n",
        "    y_epoch[\"train\"][\"pred\"] = torch.zeros((N_EPOCHS, train_baches_epoch, BATCH_SIZE, FEATURES))\n",
        "    y_epoch[\"val\"][\"label\"] = torch.zeros((N_EPOCHS, val_baches_epoch, BATCH_SIZE, FEATURES))\n",
        "    y_epoch[\"val\"][\"pred\"] = torch.zeros((N_EPOCHS, val_baches_epoch, BATCH_SIZE, FEATURES))\n",
        "\n",
        "    return y_epoch, score, loss\n",
        "\n",
        "y_epoch, score, loss = init_arrays(674, 168)\n",
        "\n",
        "print(y_epoch[\"train\"][\"label\"][N_EPOCHS-1][674-1][BATCH_SIZE-1][16])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABlXwFuhIy15"
      },
      "outputs": [],
      "source": [
        "def eval_score(Y_true:Tensor, Y_pred:Tensor, threshold:float):\n",
        "    Y_true = Y_true.numpy().reshape((-1,FEATURES))\n",
        "    Y_pred = (Y_pred.numpy() > .2).astype(float).reshape((-1,FEATURES))\n",
        "    return fbeta_score(Y_true,Y_pred,beta=2, average=\"samples\")\n",
        "\n",
        "\n",
        "t1, t2 = torch.zeros(FEATURES), torch.zeros(FEATURES)\n",
        "t1[4], t2[7] = 1, 1\n",
        "Y_true = torch.cat([t1,t2])\n",
        "Y_pred = torch.cat([t2,t1])*0.8\n",
        "print(Y_true)\n",
        "print(Y_pred)\n",
        "eval_score(Y_true, Y_pred, 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vap7R9gUIy16"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkUB6naQIy16"
      },
      "outputs": [],
      "source": [
        "if RunningInCOLAB:\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ia_yvY8NlJ_7"
      },
      "outputs": [],
      "source": [
        "# def train_model(dl_train, dl_val, version, model, optimizer, loss_fn, lr_scheduler, results_checkpoint, checkpoint):\n",
        "checkpoint = {}\n",
        "results_checkpoint = {}\n",
        "\n",
        "train_baches_epoch, val_baches_epoch = 675, 169\n",
        "\n",
        "y_epoch, score, loss = init_arrays(train_baches_epoch, val_baches_epoch)\n",
        "epoch_start = 0\n",
        "if results_checkpoint:\n",
        "    train_results = deepcopy(results_checkpoint)\n",
        "    epoch_start = checkpoint['epoch']\n",
        "    max_accuracy = train_results[\"score_val\"]\n",
        "    lr_scheduler = checkpoint['lr_scheduler']\n",
        "    \n",
        "Y_val, Y_hat = torch.zeros(FEATURES), torch.zeros(FEATURES)\n",
        "best_loss_val, best_score_val = torch.inf, 0\n",
        "Y_thresh_val = 0.2\n",
        "batch_loss = torch.inf\n",
        "for epoch in range(epoch_start, N_EPOCHS):\n",
        "\n",
        "    for idx, (X, Y) in enumerate(tqdm(dl_train, leave=False)):\n",
        "        Y_hat, batch_loss = train_batch(X, Y, model, loss_fn, optimizer)\n",
        "        loss[\"train\"][epoch][idx] = batch_loss\n",
        "        y_epoch[\"train\"][\"pred\"][epoch][idx] = Y_hat\n",
        "        y_epoch[\"train\"][\"label\"][epoch][idx] = Y\n",
        "        if idx > 0 and idx % LR_STEP_SIZE == 0:\n",
        "            avg_loss = loss[\"train\"][epoch][idx-LR_STEP_SIZE:idx+1].mean()\n",
        "            print('Train Loss: {:.6f}'.format(batch_loss))\n",
        "            lr_scheduler.step(metrics=avg_loss)\n",
        "        #break\n",
        "\n",
        "    for idx, (X, Y) in enumerate(tqdm(dl_val, leave=False)):\n",
        "        Y_hat, batch_loss = compute_val_loss(X, Y, model, loss_fn)\n",
        "        loss[\"val\"][epoch][idx] = batch_loss\n",
        "        y_epoch[\"val\"][\"pred\"][epoch][idx] = Y_hat\n",
        "        y_epoch[\"val\"][\"label\"][epoch][idx] = Y\n",
        "        #break\n",
        "    \n",
        "\n",
        "    score['train'][epoch] = eval_score(y_epoch[\"train\"][\"label\"][epoch],\n",
        "                                       y_epoch[\"train\"][\"pred\"][epoch], Y_thresh_val)\n",
        "    score['val'][epoch] = eval_score(y_epoch[\"val\"][\"label\"][epoch],\n",
        "                                     y_epoch[\"val\"][\"pred\"][epoch], Y_thresh_val)\n",
        "\n",
        "    avg_loss_train = loss[\"train\"][epoch].mean()\n",
        "    avg_loss_val = loss[\"val\"][epoch].mean()\n",
        "\n",
        "    best_loss_val = avg_loss_val if avg_loss_val < best_loss_val else best_loss_val\n",
        "    best_score_val = score['val'][epoch] if avg_loss_val < score['val'][epoch] else best_score_val\n",
        "\n",
        "\n",
        "    print(\n",
        "        f\"epoch: {epoch}/{N_EPOCHS} -- train loss: {avg_loss_train}, \"\n",
        "        f\"val loss: {avg_loss_val}\"\n",
        "        f\" -- train fbeta_score: {score['train'][epoch]}, \"\n",
        "        f\"val fbeta_score: {score['val'][epoch]}\"\n",
        "    )\n",
        "\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'loss': best_loss_val,\n",
        "        'max_accuracy': best_score_val,\n",
        "        'lr_scheduler': lr_scheduler.state_dict(),\n",
        "        'config': config\n",
        "    }\n",
        "\n",
        "    train_results = {\n",
        "        \"loss\": loss,\n",
        "        \"score\": score,\n",
        "    }\n",
        "    save_train_checkpoint(checkpoint, train_results, VERSION)\n",
        "    #break\n",
        "\n",
        "checkpoint = {}\n",
        "\n",
        "\n",
        "#train_model(dl_train, dl_val, VERSION, model, optimizer, loss_fn, lr_scheduler,results, checkpoint)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHqChyNmMBUf"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFYCbd8vyTYj"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from google.colab import runtime\n",
        "\n",
        "runtime.unassign()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MD0eTOV_uDiI"
      },
      "outputs": [],
      "source": [
        "#model = torch.load(\"resnet18_0.pth\")\n",
        "#train_results = pickltranse.load(open(\"train_results_0.pkl\", \"rb\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGLu0IGpVVLS"
      },
      "source": [
        "# Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3M0udvluDiK"
      },
      "outputs": [],
      "source": [
        "oss_train = train_results[\"loss_train\"]\n",
        "loss_val = train_results[\"loss_val\"]\n",
        "score_train = train_results[\"score_train\"]\n",
        "score_val = train_results[\"score_val\"]\n",
        "\n",
        "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Loss\", \"Fbeta scores\"))\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=list(range(len(loss_train))),\n",
        "        y=loss_train,\n",
        "        name=\"loss_train\",\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=list(range(len(loss_val))),\n",
        "        y=loss_val,\n",
        "        name=\"loss_val\",\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=list(range(len(score_train))),\n",
        "        y=score_train,\n",
        "        name=\"score_train\",\n",
        "    ),\n",
        "    row=1, col=2\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=list(range(len(score_val))),\n",
        "        y=score_val,\n",
        "        name=\"score_val\",\n",
        "    ),\n",
        "    row=1, col=2\n",
        ")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KET5kS_CuDiM"
      },
      "outputs": [],
      "source": [
        "Y_hat_val = np.array(train_results[\"Y_hat_val\"])\n",
        "Y_val = np.array(train_results[\"Y_val\"])\n",
        "\n",
        "pos_probas, neg_probas = [], []\n",
        "for class_, idx in encoder._cached_dict.items():\n",
        "    pos_probas.append(Y_hat_val[np.where(Y_val[:, idx] != 0), idx].mean())\n",
        "    neg_probas.append(Y_hat_val[np.where(Y_val[:, idx] == 0), idx].mean())\n",
        "go.Figure([\n",
        "    go.Bar(x=list(encoder._cached_dict),\n",
        "           y=pos_probas, name=\"Y_hat proba | Y = 1\"),\n",
        "    go.Bar(x=list(encoder._cached_dict),\n",
        "           y=neg_probas, name=\"Y_hat proba | Y = 0\")\n",
        "]).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Caby0A04uDiQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def find_best_thresholds(Y_hat, Y):\n",
        "    N_tags = Y.shape[1]\n",
        "    best_threshs = [0.2] * N_tags\n",
        "    resolution = 100\n",
        "    for jdx in tqdm(range(N_tags)):\n",
        "        best_score = 0\n",
        "        #threshs = np.zeros_like(best_threshs)\n",
        "        threshs = best_threshs.copy()\n",
        "        for kdx in range(resolution):\n",
        "            kdx /= resolution\n",
        "            threshs[jdx] = kdx\n",
        "            Y_hat_thresh = (Y_hat > threshs).astype(float)\n",
        "            score = fbeta_score(Y, Y_hat_thresh, beta=2, average=\"samples\")\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_threshs[jdx] = kdx\n",
        "\n",
        "    global_best_score = fbeta_score(\n",
        "        Y, (Y_hat > best_threshs).astype(float), beta=2, average=\"samples\")\n",
        "    print(f\"threshs: {best_threshs} -- best score: {global_best_score}\")\n",
        "\n",
        "    return best_threshs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dh9Hm0RquDiS"
      },
      "outputs": [],
      "source": [
        "threshs = find_best_thresholds(Y_hat_val, Y_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vMVucPcuDiT"
      },
      "outputs": [],
      "source": [
        "class_scores = {}\n",
        "classes = encoder.classes_\n",
        "for jdx in range(Y_val.shape[1]):\n",
        "    y_val = Y_val[:, jdx].ravel()\n",
        "    y_hat_val = (Y_hat_val[:, jdx].ravel() > threshs[jdx]).astype(float)\n",
        "    score = fbeta_score(y_val, y_hat_val, beta=2)\n",
        "    class_scores[classes[jdx]] = round(score, 4)\n",
        "\n",
        "df_score = pd.DataFrame(dict(\n",
        "    label=list(class_scores.keys()), score=list(class_scores.values()),\n",
        ")).sort_values(\"score\", ascending=False)\n",
        "fig = px.bar(df_score, x=\"label\", y=\"score\", color=\"score\")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XW9Pmf_uDiV"
      },
      "outputs": [],
      "source": [
        "fig = make_subplots(cols=5, rows=4)\n",
        "for jdx in range(Y_val.shape[1]):\n",
        "    y_val = Y_val[:, jdx].ravel()\n",
        "    y_hat_val = (Y_hat_val[:, jdx].ravel() > threshs[jdx]).astype(float)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_val, y_hat_val).ravel()\n",
        "    mat = np.array([[fn, tn], [tp, fp]])\n",
        "    col = jdx // 4+1\n",
        "    row = jdx % 4+1\n",
        "    fig.add_trace(\n",
        "        go.Heatmap(\n",
        "            z=mat, text=[[f\"fn: {fn}\", f\"tn: {tn}\"],\n",
        "                         [f\"tp: {tp}\", f\"fp: {fp}\"]],\n",
        "            texttemplate=\"%{text}\", colorscale='Viridis', name=encoder.classes_[jdx],\n",
        "            showscale=False\n",
        "        ),\n",
        "        col=col, row=row,\n",
        "    )\n",
        "    fig.update_xaxes(title=encoder.classes_[\n",
        "                     jdx], showticklabels=False, row=row, col=col)\n",
        "    fig.update_yaxes(showticklabels=False, row=row, col=col)\n",
        "\n",
        "\n",
        "fig.update_layout(\n",
        "    width=1200, height=800, title=\"Confusion matrices\",\n",
        ")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCy0FH4EuDiZ"
      },
      "outputs": [],
      "source": [
        "!echo $(ls ../input/planets-dataset/planet/planet/test-jpg | wc - l) + $(ls ../input/planets-dataset/test-jpg-additional/test-jpg-additional | wc - l)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJoGPYgauDic"
      },
      "outputs": [],
      "source": [
        "def get_test_data(idx_tta):\n",
        "    path_test_table = \"../input/planets-dataset/planet/planet\"\n",
        "    path_test_file_1 = \"../input/planets-dataset/planet/planet/test-jpg\"\n",
        "    path_test_file_2 = \"../input/planets-dataset/test-jpg-additional/test-jpg-additional\"\n",
        "    file_count = len(os.listdir(path_test_file_1)) + \\\n",
        "        len(os.listdir(path_test_file_2))\n",
        "    df_test = pd.read_csv(os.path.join(\n",
        "        path_test_table, \"sample_submission.csv\"))\n",
        "\n",
        "    assert df_test.shape[0] == file_count  # sanity check\n",
        "\n",
        "    ohe_tags_test = np.zeros((df_test.shape[0], 17))\n",
        "    _, transform_val = get_transforms()\n",
        "    ds_test = AmazonDataset(\n",
        "        df_test, ohe_tags_test, transform_val, path=[\n",
        "            path_test_file_1, path_test_file_2],\n",
        "        is_train=False, idx_tta=idx_tta\n",
        "    )\n",
        "    dl_test = DataLoader(\n",
        "        ds_test, shuffle=False, batch_size=32, collate_fn=ds_test.collate_fn\n",
        "    )\n",
        "\n",
        "    return dl_test, df_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8fqPi2muDie"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def batch_predict(model, X):\n",
        "    model.eval()\n",
        "    Y = model(X)\n",
        "    return Y.detach().float().cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51YOt1XsuDif"
      },
      "outputs": [],
      "source": [
        "Y_hat_test = []\n",
        "for idx_tta in range(6):\n",
        "    Y_hat_test_tta = []\n",
        "    dl_test, df_test = get_test_data(idx_tta)\n",
        "    for X, _ in tqdm(dl_test):\n",
        "        Y_hat_test_batch = batch_predict(model, X)\n",
        "        Y_hat_test_tta.extend(Y_hat_test_batch)\n",
        "    Y_hat_test.append(Y_hat_test_tta)\n",
        "Y_hat_test = np.mean(np.array(Y_hat_test), axis=0)\n",
        "Y_hat_test = (Y_hat_test > threshs).astype(float)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmDYnAwPuDim"
      },
      "outputs": [],
      "source": [
        "Y_hat_test_inv = encoder.inverse_transform(Y_hat_test)\n",
        "test_tags = []\n",
        "for row in Y_hat_test_inv:\n",
        "    tags = \" \".join(row)\n",
        "    test_tags.append(tags)\n",
        "\n",
        "df_test[\"tags\"] = test_tags\n",
        "df_test.to_csv(\"my_sample_submission.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRBcPu-s3t-F"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "7R7FgPDy0Lpi",
        "ddEsH8tA0Lp3",
        "IFlVwBvw0LqC",
        "K1yn3eXP0LqD",
        "CvLrcH549YXL"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}